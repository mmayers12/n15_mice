{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep for other enrichment Algorithms (in Bioconductor [R]): topGO (and maybe deseq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "import shelve\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from adjustText import adjust_text\n",
    "\n",
    "from scripts import utils\n",
    "from scripts.analysis import build_loci\n",
    "from scripts.analysis.DBInfo import DBInfo\n",
    "\n",
    "BASE = '../data'\n",
    "\n",
    "\n",
    "db_info = DBInfo(\"compil_mgm\")\n",
    "metadata = build_loci.read_metadata(os.path.join(BASE,\"metadata.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UL_Rg_1016_N_1',\n",
       " 'UL_Rg_1019_N_1',\n",
       " 'UL_Rg_1021_N_1',\n",
       " 'UL_Mix_1021_1',\n",
       " 'UL_Mix_1021_N_1',\n",
       " 'UL_Mix_1019_1',\n",
       " 'UL_Mix_1019_N_1',\n",
       " 'UL_Mix_1016_1',\n",
       " 'UL_Mix_1016_N_1',\n",
       " 'US_Mix_1021_1',\n",
       " 'US_Mix_1021_N_1',\n",
       " 'US_Mix_1019_1',\n",
       " 'US_Mix_1019_N_1',\n",
       " 'US_Mix_1016_1',\n",
       " 'US_Mix_1016_N_1',\n",
       " 'UL_Mix_1121_1',\n",
       " 'UL_Mix_1121_N_1',\n",
       " 'US_Mix_1121_1',\n",
       " 'US_Mix_1121_N_1',\n",
       " 'UL_Mix_1121_2',\n",
       " 'UL_Mix_1121_N_2',\n",
       " 'AL_Mix_1120_1',\n",
       " 'AL_Mix_1120_N_1',\n",
       " 'CL_Mix_1120_1',\n",
       " 'CL_Mix_1120_N_1',\n",
       " 'UL_Mix_1121_3',\n",
       " 'UL_Mix_1121_N_3',\n",
       " 'UL_Mix_1121_4',\n",
       " 'UL_Mix_1121_N_4',\n",
       " 'UL_Mix_1021_2',\n",
       " 'UL_Mix_1021_N_2',\n",
       " 'UL_Mix_1111_1',\n",
       " 'UL_Mix_1111_N_1',\n",
       " 'UL_Rg_1111_N_1',\n",
       " 'UL_Mix_1111_2',\n",
       " 'UL_Mix_1111_N_2',\n",
       " 'UL_Mix_1111_3',\n",
       " 'UL_Mix_1111_N_3',\n",
       " 'CL_Mix_1111_1',\n",
       " 'CL_Mix_1111_N_1',\n",
       " 'AL_Tc_N14_1',\n",
       " 'UL_Mix_Pool_1',\n",
       " 'UL_Mix_Pool_N_1',\n",
       " 'UL_Tc_Pool_1',\n",
       " 'CL_Mix_Pool_1',\n",
       " 'CL_Mix_Pool_N_1',\n",
       " 'DL_Mix_Pool_1',\n",
       " 'DL_Mix_Pool_N_1',\n",
       " 'AL_Mix_Pool_1',\n",
       " 'AL_Mix_Pool_N_1',\n",
       " 'UL_Tc_Pool_2',\n",
       " 'CL_Mix_Pool_2',\n",
       " 'CL_Mix_Pool_N_2',\n",
       " 'DL_Mix_Pool_2',\n",
       " 'DL_Mix_Pool_N_2',\n",
       " 'CL_Mix_Pool_3',\n",
       " 'CL_Mix_Pool_N_3',\n",
       " 'DL_Mix_Pool_3',\n",
       " 'DL_Mix_Pool_N_3',\n",
       " 'CL_Mix_Pool_4',\n",
       " 'CL_Mix_Pool_N_4',\n",
       " 'DL_Mix_Pool_4',\n",
       " 'DL_Mix_Pool_N_4',\n",
       " 'CL_Mix_Pool_5',\n",
       " 'CL_Mix_Pool_N_5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_names = list(metadata.columns)\n",
    "samp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unenr_grouped_loci = utils.load(os.path.join(BASE,\"unenriched_grouped_loci.pkl.gz\"))\n",
    "enr_grouped_loci = utils.load(os.path.join(BASE,\"enriched_grouped_loci_filt1.pkl.gz\"))\n",
    "grouped_loci = utils.load(os.path.join(BASE,\"grouped_loci_filt1.pkl.gz\"))\n",
    "\n",
    "annotations = {locus.cluster_id:locus.annotations['go'] for locus in grouped_loci if 'go' in locus.annotations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UL_Mix_1111_1',\n",
       " 'UL_Mix_1111_2',\n",
       " 'UL_Mix_1111_3',\n",
       " 'UL_Mix_1111_N_1',\n",
       " 'UL_Mix_1111_N_2',\n",
       " 'UL_Mix_1111_N_3',\n",
       " 'UL_Mix_1121_1',\n",
       " 'UL_Mix_1121_2',\n",
       " 'UL_Mix_1121_3',\n",
       " 'UL_Mix_1121_4',\n",
       " 'UL_Mix_1121_N_1',\n",
       " 'UL_Mix_1121_N_2',\n",
       " 'UL_Mix_1121_N_3',\n",
       " 'UL_Mix_1121_N_4',\n",
       " 'UL_Mix_Pool_1',\n",
       " 'UL_Mix_Pool_N_1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unenr_keys = set()\n",
    "for pc in unenr_grouped_loci:\n",
    "    for samp in pc.quantification.keys():\n",
    "        unenr_keys.add(samp)\n",
    "unenr_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CL_Mix_Pool_1',\n",
       " 'CL_Mix_Pool_2',\n",
       " 'CL_Mix_Pool_3',\n",
       " 'CL_Mix_Pool_4',\n",
       " 'CL_Mix_Pool_5',\n",
       " 'CL_Mix_Pool_N_1',\n",
       " 'CL_Mix_Pool_N_2',\n",
       " 'CL_Mix_Pool_N_3',\n",
       " 'CL_Mix_Pool_N_4',\n",
       " 'CL_Mix_Pool_N_5'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enr_keys = set()\n",
    "for pc in enr_grouped_loci:\n",
    "    for samp in pc.quantification.keys():\n",
    "        enr_keys.add(samp)\n",
    "enr_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unenr_keys = sorted(list(unenr_keys), key=lambda x: (x.split('_')[2], x.split('_')[-1], x.split('_')[-2]=='N'))\n",
    "enr_keys = sorted(list(enr_keys), key=lambda x: (x.split('_')[2], x.split('_')[-1], x.split('_')[-2]=='N'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## topGO needs a gene2go mapping\n",
    "\n",
    "mapping consists of:  \n",
    "    Gene1\\tGO:1, GO:2, GO:3  \n",
    "    Gene2\\tGO:3, GO:5, GO:7, GO:8, GO:9  \n",
    "etc.\n",
    "\n",
    "Will use locus cluster_id numbers for gene names as those are unique identifiers for our protein clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_gene2goMap(grouped_loci, name):\n",
    "    annotations = {locus.cluster_id:locus.annotations['go'] for locus in grouped_loci if 'go' in locus.annotations}\n",
    "    with open(os.path.join(BASE, name+'.map'), 'w') as fout:\n",
    "        for locus, terms in annotations.items():\n",
    "            fout.write(\"{}\\t\".format(locus))\n",
    "            for i, term in enumerate(terms):\n",
    "                if i == 0:\n",
    "                    fout.write('{}'.format(term))\n",
    "                else:\n",
    "                    fout.write(',{}'.format(term))\n",
    "            fout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_gene2goMap(grouped_loci, 'clusterID2GO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Metadata\n",
    "\n",
    "Make an un-cluttered version of the metadata, removing certain no-loger-needed bits of info (like paths to files that have already been processed).  Also, add a few new column for technical replicates.  This will make the info easier ot work with in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp_names = list(unenr_keys+enr_keys)\n",
    "\n",
    "met1 = metadata[samp_names].T\n",
    "\n",
    "grpd = met1.groupby(['enriched', 'n15'])\n",
    "\n",
    "for grp, data in grpd:\n",
    "    for i, samp in enumerate( data.T ):\n",
    "        met1.loc[samp, 'technical'] = i+1\n",
    "\n",
    "met1 = met1.drop(['census', 'comb_dta', 'h_dta', 'l_dta', 'path'], axis=1)\n",
    "met1 = met1.sort_values(['enriched', 'n15', 'technical'])\n",
    "met1.to_csv(os.path.join(BASE, 'filt_metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ensuring that pairs are correctly labeled together, and pulling out sets of sample name keys\n",
    "sample_pairs = met1.reset_index().set_index(['enriched', 'technical']).sort_index().groupby(level=[0,1])\n",
    "\n",
    "pairs = []\n",
    "for x, y in sample_pairs:\n",
    "    pairs.append(list(y['index'].values))\n",
    "sample_names = list(chain(*pairs))\n",
    "\n",
    "n14_samps = [x[0] for x in pairs]\n",
    "n15_samps = [x[1] for x in pairs]\n",
    "\n",
    "n14_un_samps = [x for x in n14_samps if x.startswith('UL_')]\n",
    "n15_un_samps = [x for x in n15_samps if x.startswith('UL_')]\n",
    "\n",
    "n14_enr_samps = [x for x in n14_samps if x.startswith('CL_')]\n",
    "n15_enr_samps = [x for x in n15_samps if x.startswith('CL_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put the counts into a dataframe in case we decide to use DESEQ2.  Use Back_calc, in which N15 counts are calculated\n",
    "# via ms1 ratio by taking N14_couts * N15/N14_ratio when a ratio is avaliable\n",
    "loci = defaultdict(dict)\n",
    "for cluster in grouped_loci:\n",
    "    for samp, values in cluster.quantification.items():\n",
    "        loci[cluster.cluster_id].update({samp: int(np.round(values['back_calc']))})\n",
    "\n",
    "count_df = pd.DataFrame(loci).T.fillna(0)\n",
    "count_df = count_df.T.reindex(met1.index).T\n",
    "\n",
    "count_df.to_csv(os.path.join(BASE,'counts.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the p-value for each cluster\n",
    "\n",
    "TopGO can use this for certain tests like Fisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cluster_pvals(grouped_loci):\n",
    "    loci = defaultdict(dict)\n",
    "    for locus in grouped_loci:\n",
    "        loci[locus.cluster_id].update({'ratio': locus.avg_ratio, 'p_value': locus.p_value})\n",
    "    return(pd.DataFrame(loci).T.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_cluster_pvals(unenr_grouped_loci).to_csv(os.path.join(BASE, 'unenriched_pvals.csv'))\n",
    "get_cluster_pvals(enr_grouped_loci).to_csv(os.path.join(BASE, 'enriched_pvals.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build_loci.get_annotation_df(unenr_grouped_loci).to_csv(os.path.join(BASE, 'unenriched_annot.csv'))\n",
    "build_loci.get_annotation_df(enr_grouped_loci).to_csv(os.path.join(BASE, 'enriched_annot.csv'))\n",
    "build_loci.get_annotation_df(grouped_loci).to_csv(os.path.join(BASE, 'loci_annot.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info to determine which loci show up in which sample gorups \n",
    "\n",
    "This will allow for fihser test comparisons of enriched vs unenriched samples in topGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign groups to each locus\n",
    "groups = {'RT-Enriched': n14_enr_samps, 'RAG-Enriched': n15_enr_samps, 'RT-Unenriched': n14_un_samps, 'RAG-Unenriched': n15_un_samps}\n",
    "\n",
    "for locus in grouped_loci:\n",
    "    locus.group = []\n",
    "    samples_in_locus = {sample for sample, quant in locus.quantification.items() if (quant['ratio'] != 0 or quant['counts'] >= 5)}\n",
    "    for group, members in groups.items():\n",
    "        if set(members) & samples_in_locus:\n",
    "            locus.group.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups = dict()\n",
    "for locus in grouped_loci:\n",
    "    groups.update({locus.cluster_id: {\"RT_Enriched\": \"RT-Enriched\" in locus.group,\n",
    "                   \"RAG_Enriched\": \"RAG-Enriched\" in locus.group, \"RT_Unenriched\": \"RT-Unenriched\" in locus.group,\n",
    "                   \"RAG_Unenriched\": \"RAG-Unenriched\" in locus.group}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_df = pd.DataFrame.from_dict(groups).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "group_df.to_csv(os.path.join(BASE,'groups.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
